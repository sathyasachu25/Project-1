{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68Cdhi5B-d1n"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Advanced Time Series Forecasting with Deep Learning and Attention Mechanisms\n",
        "\n",
        "This script implements the entire project described in the Cultus Skills Center brief.\n",
        "\n",
        "Main components\n",
        "---------------\n",
        "1. Synthetic multivariate time series generation (>= 5000 observations, >= 5 features)\n",
        "2. Data preprocessing: scaling, missing values, sequence creation\n",
        "3. Baseline models:\n",
        "   - SARIMA (univariate)\n",
        "   - Simple LSTM without attention\n",
        "4. Deep learning model with explicit Bahdanau attention on top of LSTM\n",
        "5. Hyperparameter optimization for the attention model using Optuna\n",
        "6. Evaluation using RMSE, MAE, MAPE on a held-out test set\n",
        "7. Attention weights analysis for interpretability\n",
        "\n",
        "You can run this file as a script or copy sections into a Jupyter / Colab notebook.\n",
        "\"\"\"\n",
        "\n",
        "# ===============================\n",
        "# 1. Imports and global settings\n",
        "# ===============================\n",
        "import os\n",
        "import random\n",
        "import math\n",
        "from dataclasses import dataclass\n",
        "from typing import Tuple, Dict\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, callbacks, optimizers\n",
        "\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "\n",
        "import optuna\n",
        "\n",
        "# For reproducibility\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (10, 4)\n",
        "\n",
        "\n",
        "# =====================================\n",
        "# 2. Utility metrics and data functions\n",
        "# =====================================\n",
        "\n",
        "def mape(y_true, y_pred):\n",
        "    \"\"\"Mean Absolute Percentage Error (safe for zeros).\"\"\"\n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "    eps = 1e-8\n",
        "    return np.mean(np.abs((y_true - y_pred) / (np.abs(y_true) + eps))) * 100.0\n",
        "\n",
        "\n",
        "def rmse(y_true, y_pred):\n",
        "    \"\"\"Root Mean Squared Error.\"\"\"\n",
        "    return math.sqrt(mean_squared_error(y_true, y_pred))\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class DatasetSplits:\n",
        "    \"\"\"Container for time series splits and scalers.\"\"\"\n",
        "    X_train: np.ndarray\n",
        "    y_train: np.ndarray\n",
        "    X_val: np.ndarray\n",
        "    y_val: np.ndarray\n",
        "    X_test: np.ndarray\n",
        "    y_test: np.ndarray\n",
        "    scaler: StandardScaler\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# 3. Synthetic multivariate time series source\n",
        "# ============================================\n",
        "\n",
        "def generate_synthetic_multivariate_series(n_steps: int = 7000) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Generate a synthetic multivariate time series with:\n",
        "    - trend\n",
        "    - seasonality\n",
        "    - regime changes\n",
        "    - noise\n",
        "    Returns a DataFrame with at least 6 features.\n",
        "    \"\"\"\n",
        "    time = np.arange(n_steps)\n",
        "\n",
        "    # Base signal with trend + yearly seasonality + weekly seasonality\n",
        "    trend = 0.0008 * time ** 1.2\n",
        "    seasonal_365 = 10 * np.sin(2 * np.pi * time / 365)\n",
        "    seasonal_7 = 2 * np.sin(2 * np.pi * time / 7)\n",
        "\n",
        "    # Regime change around 2/3 of the series\n",
        "    regime = np.where(time > n_steps * 2 / 3, 5.0, 0.0)\n",
        "\n",
        "    base_series = 50 + trend + seasonal_365 + seasonal_7 + regime\n",
        "\n",
        "    # Additional correlated features\n",
        "    feat_1 = base_series + np.random.normal(0, 1.0, n_steps)           # noisy version\n",
        "    feat_2 = 0.5 * base_series + 10 * np.sin(2 * np.pi * time / 30)    # another seasonal mix\n",
        "    feat_3 = np.roll(base_series, 3)                                   # lagged\n",
        "    feat_4 = np.roll(base_series, 7)                                   # lagged\n",
        "    feat_5 = np.random.normal(0, 5, n_steps)                           # mostly noise\n",
        "    feat_6 = trend * 2 + np.random.normal(0, 0.5, n_steps)             # strong trend feature\n",
        "\n",
        "    df = pd.DataFrame({\n",
        "        \"target\": base_series + np.random.normal(0, 1.5, n_steps),\n",
        "        \"feat_1\": feat_1,\n",
        "        \"feat_2\": feat_2,\n",
        "        \"feat_3\": feat_3,\n",
        "        \"feat_4\": feat_4,\n",
        "        \"feat_5\": feat_5,\n",
        "        \"feat_6\": feat_6,\n",
        "    })\n",
        "\n",
        "    # Introduce a few random missing values and then fill them\n",
        "    for col in df.columns:\n",
        "        idx = np.random.choice(n_steps, size=int(0.01 * n_steps), replace=False)\n",
        "        df.loc[idx, col] = np.nan\n",
        "    df = df.interpolate().ffill().bfill()\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "# =================================\n",
        "# 4. Preprocessing & window maker\n",
        "# =================================\n",
        "\n",
        "def create_windows(\n",
        "    data: pd.DataFrame,\n",
        "    seq_len: int,\n",
        "    target_col: str = \"target\"\n",
        ") -> Tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"\n",
        "    Convert a multivariate time series into supervised sequences.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    data : pd.DataFrame\n",
        "        Multivariate time series with 'target' column.\n",
        "    seq_len : int\n",
        "        Number of time steps in the input sequence window.\n",
        "    target_col : str\n",
        "        Name of the target column.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    X : np.ndarray\n",
        "        Shape (n_samples, seq_len, n_features).\n",
        "    y : np.ndarray\n",
        "        Shape (n_samples,).\n",
        "    \"\"\"\n",
        "    values = data.values\n",
        "    target_idx = data.columns.get_loc(target_col)\n",
        "\n",
        "    X, y = [], []\n",
        "    for i in range(len(values) - seq_len):\n",
        "        X.append(values[i:i + seq_len])\n",
        "        y.append(values[i + seq_len, target_idx])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "\n",
        "def prepare_datasets(\n",
        "    df: pd.DataFrame,\n",
        "    seq_len: int = 48,\n",
        "    target_col: str = \"target\",\n",
        "    train_ratio: float = 0.7,\n",
        "    val_ratio: float = 0.15,\n",
        ") -> DatasetSplits:\n",
        "    \"\"\"\n",
        "    Scale features, split into train/val/test, and create windows.\n",
        "\n",
        "    Returns DatasetSplits containing numpy arrays ready for modeling.\n",
        "    \"\"\"\n",
        "    n = len(df)\n",
        "    train_end = int(n * train_ratio)\n",
        "    val_end = int(n * (train_ratio + val_ratio))\n",
        "\n",
        "    df_train = df.iloc[:train_end]\n",
        "    df_val = df.iloc[train_end:val_end]\n",
        "    df_test = df.iloc[val_end:]\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(df_train)\n",
        "\n",
        "    df_train_scaled = pd.DataFrame(scaler.transform(df_train), columns=df.columns)\n",
        "    df_val_scaled = pd.DataFrame(scaler.transform(df_val), columns=df.columns)\n",
        "    df_test_scaled = pd.DataFrame(scaler.transform(df_test), columns=df.columns)\n",
        "\n",
        "    X_train, y_train = create_windows(df_train_scaled, seq_len, target_col)\n",
        "    X_val, y_val = create_windows(df_val_scaled, seq_len, target_col)\n",
        "    X_test, y_test = create_windows(df_test_scaled, seq_len, target_col)\n",
        "\n",
        "    return DatasetSplits(\n",
        "        X_train=X_train, y_train=y_train,\n",
        "        X_val=X_val, y_val=y_val,\n",
        "        X_test=X_test, y_test=y_test,\n",
        "        scaler=scaler,\n",
        "    )\n",
        "\n",
        "\n",
        "# ============================\n",
        "# 5. Baseline: SARIMA model\n",
        "# ============================\n",
        "\n",
        "def run_sarima_baseline(\n",
        "    df: pd.DataFrame,\n",
        "    train_ratio: float = 0.7,\n",
        "    val_ratio: float = 0.15,\n",
        "    seasonal_period: int = 365\n",
        ") -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Fit a SARIMA model on the target series and evaluate on the test set.\n",
        "\n",
        "    For simplicity we use manually chosen (p,d,q)(P,D,Q,s) orders that work\n",
        "    reasonably for this synthetic data.\n",
        "    \"\"\"\n",
        "    series = df[\"target\"].values\n",
        "    n = len(series)\n",
        "    train_end = int(n * train_ratio)\n",
        "    val_end = int(n * (train_ratio + val_ratio))\n",
        "\n",
        "    train_series = series[:val_end]   # train on train+val\n",
        "    test_series = series[val_end:]\n",
        "\n",
        "    # You could tune these hyperparameters using AIC, but we fix them here.\n",
        "    order = (1, 1, 1)\n",
        "    seasonal_order = (1, 1, 1, seasonal_period)\n",
        "\n",
        "    print(\"Fitting SARIMA baseline ...\")\n",
        "    sarima_model = SARIMAX(\n",
        "        train_series,\n",
        "        order=order,\n",
        "        seasonal_order=seasonal_order,\n",
        "        enforce_stationarity=False,\n",
        "        enforce_invertibility=False,\n",
        "    )\n",
        "    sarima_res = sarima_model.fit(disp=False)\n",
        "\n",
        "    # Forecast the length of the test set\n",
        "    forecast = sarima_res.forecast(steps=len(test_series))\n",
        "\n",
        "    metrics = {\n",
        "        \"RMSE\": rmse(test_series, forecast),\n",
        "        \"MAE\": mean_absolute_error(test_series, forecast),\n",
        "        \"MAPE\": mape(test_series, forecast),\n",
        "    }\n",
        "    print(\"SARIMA baseline metrics on test set:\")\n",
        "    print(metrics)\n",
        "\n",
        "    return metrics\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "# 6. Baseline: Simple LSTM (no attention)\n",
        "# ==========================================\n",
        "\n",
        "def build_simple_lstm_model(\n",
        "    input_shape: Tuple[int, int],\n",
        "    lstm_units: int = 64,\n",
        "    dropout: float = 0.2,\n",
        "    learning_rate: float = 1e-3\n",
        ") -> tf.keras.Model:\n",
        "    \"\"\"\n",
        "    Build a simple LSTM model without attention for baseline comparison.\n",
        "    \"\"\"\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    x = layers.LSTM(lstm_units, return_sequences=False)(inputs)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    outputs = layers.Dense(1)(x)\n",
        "\n",
        "    model = models.Model(inputs, outputs)\n",
        "    optimizer = optimizers.Adam(learning_rate=learning_rate)\n",
        "    model.compile(optimizer=optimizer, loss=\"mse\")\n",
        "    return model\n",
        "\n",
        "\n",
        "def train_and_evaluate_simple_lstm(\n",
        "    splits: DatasetSplits,\n",
        "    epochs: int = 20,\n",
        "    batch_size: int = 64\n",
        ") -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Train the simple LSTM baseline and evaluate on the test set.\n",
        "    \"\"\"\n",
        "    input_shape = splits.X_train.shape[1:]\n",
        "    model = build_simple_lstm_model(input_shape)\n",
        "\n",
        "    es = callbacks.EarlyStopping(\n",
        "        monitor=\"val_loss\",\n",
        "        patience=5,\n",
        "        restore_best_weights=True\n",
        "    )\n",
        "\n",
        "    history = model.fit(\n",
        "        splits.X_train, splits.y_train,\n",
        "        validation_data=(splits.X_val, splits.y_val),\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size,\n",
        "        verbose=1,\n",
        "        callbacks=[es],\n",
        "    )\n",
        "\n",
        "    preds = model.predict(splits.X_test).flatten()\n",
        "    y_true = splits.y_test\n",
        "\n",
        "    metrics = {\n",
        "        \"RMSE\": rmse(y_true, preds),\n",
        "        \"MAE\": mean_absolute_error(y_true, preds),\n",
        "        \"MAPE\": mape(y_true, preds),\n",
        "    }\n",
        "    print(\"Simple LSTM baseline metrics on test set:\")\n",
        "    print(metrics)\n",
        "\n",
        "    return metrics\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "# 7. Main model: LSTM + Bahdanau Attention\n",
        "# ==========================================\n",
        "\n",
        "class BahdanauAttention(layers.Layer):\n",
        "    \"\"\"\n",
        "    Bahdanau additive attention layer.\n",
        "\n",
        "    Given encoder outputs (batch, time, features), it returns:\n",
        "    - context vector (batch, features)\n",
        "    and stores attention weights (batch, time, 1) in self.last_attention_weights\n",
        "    for later inspection.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, units: int, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.W1 = layers.Dense(units)\n",
        "        self.V = layers.Dense(1)\n",
        "        self.last_attention_weights = None\n",
        "\n",
        "    def call(self, encoder_outputs):\n",
        "        # encoder_outputs: (batch, time, features)\n",
        "        # score: (batch, time, 1)\n",
        "        score = self.V(tf.nn.tanh(self.W1(encoder_outputs)))\n",
        "        attention_weights = tf.nn.softmax(score, axis=1)  # along time dimension\n",
        "\n",
        "        context_vector = attention_weights * encoder_outputs\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1)  # sum over time\n",
        "\n",
        "        # Save attention weights for later inspection\n",
        "        self.last_attention_weights = attention_weights\n",
        "        return context_vector\n",
        "\n",
        "\n",
        "def build_lstm_attention_model(\n",
        "    input_shape: Tuple[int, int],\n",
        "    lstm_units: int,\n",
        "    attention_units: int,\n",
        "    dropout: float,\n",
        "    learning_rate: float\n",
        ") -> Tuple[tf.keras.Model, BahdanauAttention]:\n",
        "    \"\"\"\n",
        "    Build an LSTM model with Bahdanau attention on top of LSTM outputs.\n",
        "    \"\"\"\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    x = layers.LSTM(lstm_units, return_sequences=True)(inputs)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "\n",
        "    attention_layer = BahdanauAttention(attention_units, name=\"attention_layer\")\n",
        "    context_vector = attention_layer(x)\n",
        "\n",
        "    x = layers.Dense(64, activation=\"relu\")(context_vector)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    outputs = layers.Dense(1)(x)\n",
        "\n",
        "    model = models.Model(inputs, outputs)\n",
        "    optimizer = optimizers.Adam(learning_rate=learning_rate)\n",
        "    model.compile(optimizer=optimizer, loss=\"mse\")\n",
        "\n",
        "    return model, attention_layer\n",
        "\n",
        "\n",
        "# ======================================\n",
        "# 8. Hyperparameter optimization (Optuna)\n",
        "# ======================================\n",
        "\n",
        "def objective(trial, df: pd.DataFrame) -> float:\n",
        "    \"\"\"\n",
        "    Optuna objective function for tuning the LSTM+Attention model.\n",
        "\n",
        "    We sample:\n",
        "    - sequence length\n",
        "    - LSTM units\n",
        "    - attention units\n",
        "    - dropout\n",
        "    - learning rate\n",
        "    - batch size\n",
        "\n",
        "    The objective is validation RMSE.\n",
        "    \"\"\"\n",
        "    # Sample hyperparameters\n",
        "    seq_len = trial.suggest_int(\"seq_len\", 24, 72, step=12)\n",
        "    lstm_units = trial.suggest_categorical(\"lstm_units\", [32, 64, 96, 128])\n",
        "    att_units = trial.suggest_categorical(\"attention_units\", [16, 32, 64])\n",
        "    dropout = trial.suggest_float(\"dropout\", 0.1, 0.4)\n",
        "    lr = trial.suggest_loguniform(\"lr\", 1e-4, 5e-3)\n",
        "    batch_size = trial.suggest_categorical(\"batch_size\", [32, 64, 128])\n",
        "\n",
        "    # Prepare data for this sequence length\n",
        "    splits = prepare_datasets(df, seq_len=seq_len)\n",
        "\n",
        "    input_shape = splits.X_train.shape[1:]\n",
        "    model, _ = build_lstm_attention_model(\n",
        "        input_shape=input_shape,\n",
        "        lstm_units=lstm_units,\n",
        "        attention_units=att_units,\n",
        "        dropout=dropout,\n",
        "        learning_rate=lr\n",
        "    )\n",
        "\n",
        "    es = callbacks.EarlyStopping(\n",
        "        monitor=\"val_loss\",\n",
        "        patience=5,\n",
        "        restore_best_weights=True\n",
        "    )\n",
        "\n",
        "    model.fit(\n",
        "        splits.X_train, splits.y_train,\n",
        "        validation_data=(splits.X_val, splits.y_val),\n",
        "        epochs=50,\n",
        "        batch_size=batch_size,\n",
        "        verbose=0,\n",
        "        callbacks=[es]\n",
        "    )\n",
        "\n",
        "    # Evaluate on validation set\n",
        "    val_preds = model.predict(splits.X_val, verbose=0).flatten()\n",
        "    val_rmse = rmse(splits.y_val, val_preds)\n",
        "\n",
        "    return val_rmse\n",
        "\n",
        "\n",
        "def optimize_hyperparameters(df: pd.DataFrame, n_trials: int = 15):\n",
        "    \"\"\"\n",
        "    Run Optuna hyperparameter search and return the best parameters.\n",
        "    \"\"\"\n",
        "    study = optuna.create_study(direction=\"minimize\")\n",
        "    study.optimize(lambda trial: objective(trial, df), n_trials=n_trials)\n",
        "    print(\"Best trial:\")\n",
        "    print(study.best_trial.params)\n",
        "    return study.best_trial.params\n",
        "\n",
        "\n",
        "# =============================================\n",
        "# 9. Train final attention model & evaluate\n",
        "# =============================================\n",
        "\n",
        "def train_final_attention_model(\n",
        "    df: pd.DataFrame,\n",
        "    best_params: Dict,\n",
        "    epochs: int = 50\n",
        "):\n",
        "    \"\"\"\n",
        "    Train the final LSTM+Attention model using the best hyperparameters\n",
        "    from Optuna and evaluate on the test set.\n",
        "    \"\"\"\n",
        "    seq_len = best_params[\"seq_len\"]\n",
        "\n",
        "    splits = prepare_datasets(df, seq_len=seq_len)\n",
        "\n",
        "    input_shape = splits.X_train.shape[1:]\n",
        "    model, attention_layer = build_lstm_attention_model(\n",
        "        input_shape=input_shape,\n",
        "        lstm_units=best_params[\"lstm_units\"],\n",
        "        attention_units=best_params[\"attention_units\"],\n",
        "        dropout=best_params[\"dropout\"],\n",
        "        learning_rate=best_params[\"lr\"]\n",
        "    )\n",
        "\n",
        "    es = callbacks.EarlyStopping(\n",
        "        monitor=\"val_loss\",\n",
        "        patience=7,\n",
        "        restore_best_weights=True\n",
        "    )\n",
        "\n",
        "    history = model.fit(\n",
        "        splits.X_train, splits.y_train,\n",
        "        validation_data=(splits.X_val, splits.y_val),\n",
        "        epochs=epochs,\n",
        "        batch_size=best_params[\"batch_size\"],\n",
        "        verbose=1,\n",
        "        callbacks=[es]\n",
        "    )\n",
        "\n",
        "    # Evaluate on test set\n",
        "    test_preds = model.predict(splits.X_test).flatten()\n",
        "    y_true = splits.y_test\n",
        "\n",
        "    metrics = {\n",
        "        \"RMSE\": rmse(y_true, test_preds),\n",
        "        \"MAE\": mean_absolute_error(y_true, test_preds),\n",
        "        \"MAPE\": mape(y_true, test_preds),\n",
        "    }\n",
        "    print(\"Final LSTM+Attention model metrics on test set:\")\n",
        "    print(metrics)\n",
        "\n",
        "    return model, attention_layer, splits, history, metrics, seq_len\n",
        "\n",
        "\n",
        "# ===================================\n",
        "# 10. Attention weights interpretation\n",
        "# ===================================\n",
        "\n",
        "def visualize_attention(\n",
        "    model: tf.keras.Model,\n",
        "    attention_layer: BahdanauAttention,\n",
        "    splits: DatasetSplits,\n",
        "    seq_len: int,\n",
        "    n_examples: int = 3\n",
        "):\n",
        "    \"\"\"\n",
        "    Plot attention weights over time steps for a few test examples.\n",
        "    \"\"\"\n",
        "    X_sample = splits.X_test[:n_examples]\n",
        "    y_sample = splits.y_test[:n_examples]\n",
        "\n",
        "    # Run prediction to populate attention_layer.last_attention_weights\n",
        "    _ = model.predict(X_sample, verbose=0)\n",
        "    attn_weights = attention_layer.last_attention_weights.numpy()  # (batch, time, 1)\n",
        "    attn_weights = attn_weights.squeeze(-1)  # (batch, time)\n",
        "\n",
        "    time_axis = np.arange(-seq_len, 0)\n",
        "\n",
        "    for i in range(n_examples):\n",
        "        plt.figure()\n",
        "        plt.stem(time_axis, attn_weights[i], use_line_collection=True)\n",
        "        plt.title(f\"Attention weights for test example {i+1}\\n(True value={y_sample[i]:.2f})\")\n",
        "        plt.xlabel(\"Time steps (relative to prediction)\")\n",
        "        plt.ylabel(\"Attention weight\")\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "# ================================\n",
        "# 11. Main pipeline / entry point\n",
        "# ================================\n",
        "\n",
        "def main():\n",
        "    # 1. Generate dataset\n",
        "    print(\"Generating synthetic multivariate time series ...\")\n",
        "    df = generate_synthetic_multivariate_series(n_steps=7000)\n",
        "    print(df.head())\n",
        "    print(f\"Dataset shape: {df.shape}\")\n",
        "\n",
        "    # Optional: quick visualization\n",
        "    df[\"target\"].plot(title=\"Synthetic target series\")\n",
        "    plt.show()\n",
        "\n",
        "    # 2. Baseline 1: SARIMA\n",
        "    sarima_metrics = run_sarima_baseline(df)\n",
        "\n",
        "    # 3. Baseline 2: Simple LSTM (no attention)\n",
        "    default_seq_len = 48\n",
        "    splits_for_baseline = prepare_datasets(df, seq_len=default_seq_len)\n",
        "    simple_lstm_metrics = train_and_evaluate_simple_lstm(splits_for_baseline)\n",
        "\n",
        "    # 4. Hyperparameter optimization for LSTM+Attention\n",
        "    print(\"\\nStarting Optuna hyperparameter optimization for LSTM+Attention ...\")\n",
        "    best_params = optimize_hyperparameters(df, n_trials=15)\n",
        "\n",
        "    # 5. Train final attention model\n",
        "    model, attention_layer, splits, history, attention_metrics, seq_len = \\\n",
        "        train_final_attention_model(df, best_params, epochs=60)\n",
        "\n",
        "    # 6. Plot training curves\n",
        "    plt.figure()\n",
        "    plt.plot(history.history[\"loss\"], label=\"train_loss\")\n",
        "    plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"MSE loss\")\n",
        "    plt.title(\"LSTM+Attention training & validation loss\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # 7. Attention visualization\n",
        "    print(\"\\nVisualizing attention weights on a few test examples ...\")\n",
        "    visualize_attention(model, attention_layer, splits, seq_len, n_examples=3)\n",
        "\n",
        "    # 8. Summary table\n",
        "    print(\"\\n=== Final Performance Comparison (Test Set) ===\")\n",
        "    summary_df = pd.DataFrame({\n",
        "        \"Model\": [\"SARIMA\", \"Simple LSTM\", \"LSTM + Attention (Optimized)\"],\n",
        "        \"RMSE\": [sarima_metrics[\"RMSE\"], simple_lstm_metrics[\"RMSE\"], attention_metrics[\"RMSE\"]],\n",
        "        \"MAE\": [sarima_metrics[\"MAE\"], simple_lstm_metrics[\"MAE\"], attention_metrics[\"MAE\"]],\n",
        "        \"MAPE\": [sarima_metrics[\"MAPE\"], simple_lstm_metrics[\"MAPE\"], attention_metrics[\"MAPE\"]],\n",
        "    })\n",
        "    print(summary_df)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Make TensorFlow quieter if you want:\n",
        "    os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "    main()\n"
      ]
    }
  ]
}